{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitioning Unaugmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_current_images = 75 #training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images to train:  52.5\n"
     ]
    }
   ],
   "source": [
    "train_per = 0.7 #70% of data to train\n",
    "images_to_train = no_of_current_images * train_per\n",
    "print(\"number of images to train: \",images_to_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images to test:  15.0\n"
     ]
    }
   ],
   "source": [
    "test_per = 0.20 #20 of data to train\n",
    "images_to_test = no_of_current_images * test_per\n",
    "print(\"number of images to test: \",images_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images to test:  7.5\n"
     ]
    }
   ],
   "source": [
    "val_per = 0.1 #10% of data to train\n",
    "images_to_val = no_of_current_images * val_per\n",
    "print(\"number of images to test: \",images_to_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5754523026315789 0.7554824561403508 0.280016447368421 0.45394736842105254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('data', 'train','labels','1caf4a00-9670844a-31cc-11ee-a456-e68a90e86460.txt'), 'r') as f:\n",
    "    content = f.read()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tesitng yolo with a random img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "model.predict(source = 'data/test/images/bd29bc18-e385a116-1fed-4fd3-acba-29db1659da3a.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training with custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.149 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.147 🚀 Python-3.11.4 torch-2.0.0 CPU (Apple M1)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/rei/runs/detect/train3\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011043 parameters, 3011027 gradients\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /Users/rei/runs/detect/train3', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/rei/ml/araya/yolov8_test/data/train/labels... 52 images, 1 backgrounds, 0 corrupt: 100%|██████████| 52/52 [00:00<00:00, 1496.83it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/rei/ml/araya/yolov8_test/data/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/rei/ml/araya/yolov8_test/data/val/labels... 8 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8/8 [00:00<00:00, 2645.41it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/rei/ml/araya/yolov8_test/data/val/labels.cache\n",
      "Plotting labels to /Users/rei/runs/detect/train3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/rei/runs/detect/train3\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50         0G      1.384      3.386      1.678         11        640: 100%|██████████| 4/4 [00:41<00:00, 10.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                   all          8          8    0.00333          1      0.267      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50         0G      1.262      2.943      1.474         11        640: 100%|██████████| 4/4 [00:36<00:00,  9.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "                   all          8          8    0.00333          1        0.9      0.615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50         0G      1.153      2.399      1.301         15        640: 100%|██████████| 4/4 [00:36<00:00,  9.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                   all          8          8    0.00333          1      0.962      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/50         0G      1.227      1.767      1.299         16        640: 100%|██████████| 4/4 [00:37<00:00,  9.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                   all          8          8          1       0.35      0.995      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/50         0G       1.05      1.695      1.158          7        640: 100%|██████████| 4/4 [00:36<00:00,  9.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                   all          8          8      0.611          1      0.995       0.65\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/50         0G     0.9809      1.711      1.139         16        640: 100%|██████████| 4/4 [00:36<00:00,  9.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8      0.835          1      0.995      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/50         0G      1.177      1.706      1.183         11        640: 100%|██████████| 4/4 [00:40<00:00, 10.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "                   all          8          8    0.00626          1      0.982      0.711\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/50         0G      1.191      1.522       1.15         31        640: 100%|██████████| 4/4 [00:36<00:00,  9.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8    0.00983          1      0.955      0.724\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/50         0G      1.049      1.356      1.176         11        640: 100%|██████████| 4/4 [00:38<00:00,  9.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                   all          8          8    0.00824          1      0.784      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/50         0G       1.08      1.488      1.143          8        640: 100%|██████████| 4/4 [00:36<00:00,  9.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                   all          8          8    0.00333          1      0.796      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/50         0G      1.265       1.32       1.16         10        640: 100%|██████████| 4/4 [00:36<00:00,  9.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8     0.0119          1       0.88      0.626\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/50         0G      1.051      1.379        1.1          6        640: 100%|██████████| 4/4 [00:38<00:00,  9.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                   all          8          8    0.00333          1      0.879      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/50         0G      1.141      1.399       1.18         10        640: 100%|██████████| 4/4 [00:38<00:00,  9.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                   all          8          8    0.00333          1      0.801      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/50         0G      1.165      1.355      1.186          9        640: 100%|██████████| 4/4 [00:37<00:00,  9.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "                   all          8          8     0.0109          1      0.814      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/50         0G      1.059      1.495       1.21          7        640: 100%|██████████| 4/4 [00:37<00:00,  9.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8          1      0.453       0.88      0.569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/50         0G      1.157      1.249       1.21         12        640: 100%|██████████| 4/4 [00:37<00:00,  9.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "                   all          8          8          1      0.752      0.917      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/50         0G      1.082      1.324      1.152         15        640: 100%|██████████| 4/4 [00:37<00:00,  9.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8          1      0.844      0.949      0.592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/50         0G      1.048      1.336      1.124          7        640: 100%|██████████| 4/4 [00:39<00:00,  9.86s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "                   all          8          8      0.864      0.797      0.915      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/50         0G      1.121      1.203      1.148         23        640: 100%|██████████| 4/4 [00:37<00:00,  9.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "                   all          8          8      0.862      0.875      0.927      0.602\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/50         0G      1.039        1.2      1.087         11        640: 100%|██████████| 4/4 [00:38<00:00,  9.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                   all          8          8      0.978      0.875      0.955      0.672\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/50         0G      1.021      1.139      1.096         10        640: 100%|██████████| 4/4 [00:39<00:00,  9.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "                   all          8          8      0.999      0.875      0.962      0.678\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/50         0G      1.041      1.111      1.148         11        640: 100%|██████████| 4/4 [00:36<00:00,  9.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8          1      0.987      0.995      0.769\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/50         0G      1.232      1.201      1.219         20        640: 100%|██████████| 4/4 [00:37<00:00,  9.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8       0.99      0.875      0.982      0.726\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/50         0G      1.076      1.295      1.149          6        640: 100%|██████████| 4/4 [00:44<00:00, 11.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                   all          8          8          1      0.868      0.982      0.733\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/50         0G      1.007      1.152      1.085         12        640: 100%|██████████| 4/4 [00:36<00:00,  9.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8      0.986      0.875      0.982      0.708\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/50         0G      1.045      1.146      1.093         16        640: 100%|██████████| 4/4 [00:39<00:00, 10.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          8          8          1      0.994      0.995      0.757\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/50         0G      1.012       1.11      1.067         15        640: 100%|██████████| 4/4 [00:38<00:00,  9.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          8          8      0.888      0.991      0.912      0.719\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/50         0G      0.929      1.008       1.08         13        640: 100%|██████████| 4/4 [00:37<00:00,  9.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "                   all          8          8          1      0.989      0.995      0.793\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/50         0G     0.9518      1.014      1.061          8        640: 100%|██████████| 4/4 [00:41<00:00, 10.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8          1      0.991      0.995      0.763\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/50         0G      1.029      1.216      1.082         25        640: 100%|██████████| 4/4 [00:36<00:00,  9.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8          1      0.991      0.995      0.722\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/50         0G      1.032      1.009      1.146         16        640: 100%|██████████| 4/4 [00:36<00:00,  9.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8      0.887      0.984      0.926      0.617\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/50         0G     0.8524      1.033      1.053          6        640: 100%|██████████| 4/4 [00:36<00:00,  9.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                   all          8          8      0.884          1      0.954      0.645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      33/50         0G      1.011      1.035      1.104         11        640: 100%|██████████| 4/4 [00:39<00:00,  9.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                   all          8          8      0.988          1      0.995      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      34/50         0G     0.9033     0.9358      1.081         16        640: 100%|██████████| 4/4 [00:36<00:00,  9.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8      0.882          1      0.982      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      35/50         0G     0.9664     0.9631      1.083         16        640: 100%|██████████| 4/4 [00:36<00:00,  9.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "                   all          8          8      0.983          1      0.995      0.678\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      36/50         0G     0.9176     0.9991      1.085         11        640: 100%|██████████| 4/4 [00:37<00:00,  9.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8          1      0.994      0.995      0.694\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      37/50         0G     0.9749     0.9901      1.083          9        640: 100%|██████████| 4/4 [00:42<00:00, 10.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                   all          8          8          1       0.99      0.995      0.679\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      38/50         0G      0.837     0.9195      1.016         12        640: 100%|██████████| 4/4 [00:36<00:00,  9.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                   all          8          8      0.981      0.875      0.982      0.726\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      39/50         0G     0.9317     0.9282      1.094         11        640: 100%|██████████| 4/4 [00:37<00:00,  9.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8          1      0.982      0.995      0.718\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      40/50         0G     0.7514     0.8229     0.9965         10        640: 100%|██████████| 4/4 [00:36<00:00,  9.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                   all          8          8      0.991          1      0.995       0.69\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      41/50         0G     0.8204      1.134     0.9697         10        640: 100%|██████████| 4/4 [00:36<00:00,  9.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8      0.996          1      0.995      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      42/50         0G     0.7029      1.068     0.9336          4        640: 100%|██████████| 4/4 [00:37<00:00,  9.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                   all          8          8      0.995          1      0.995      0.665\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      43/50         0G      0.774      1.039     0.9373          6        640: 100%|██████████| 4/4 [00:35<00:00,  8.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8      0.995          1      0.995      0.675\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      44/50         0G     0.6832       1.08     0.9471          4        640: 100%|██████████| 4/4 [00:35<00:00,  8.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8      0.995          1      0.995      0.719\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      45/50         0G     0.7406       1.07     0.9372          4        640: 100%|██████████| 4/4 [00:37<00:00,  9.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                   all          8          8      0.994          1      0.995      0.737\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      46/50         0G     0.8105     0.9984      0.983          4        640: 100%|██████████| 4/4 [00:35<00:00,  8.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8      0.993          1      0.995      0.731\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      47/50         0G     0.6717      1.035     0.9721          3        640: 100%|██████████| 4/4 [00:37<00:00,  9.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "                   all          8          8      0.993          1      0.995      0.735\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      48/50         0G     0.6488     0.9517     0.9423          4        640: 100%|██████████| 4/4 [00:37<00:00,  9.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          8          8      0.992          1      0.995      0.745\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      49/50         0G     0.6678     0.9043     0.9046          4        640: 100%|██████████| 4/4 [00:35<00:00,  8.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "                   all          8          8      0.992          1      0.995      0.716\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      50/50         0G     0.6363     0.8925     0.9111          4        640: 100%|██████████| 4/4 [00:35<00:00,  8.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "                   all          8          8      0.992          1      0.995      0.706\n",
      "\n",
      "50 epochs completed in 0.540 hours.\n",
      "Optimizer stripped from /Users/rei/runs/detect/train3/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /Users/rei/runs/detect/train3/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /Users/rei/runs/detect/train3/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.147 🚀 Python-3.11.4 torch-2.0.0 CPU (Apple M1)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          8          8          1      0.989      0.995      0.793\n",
      "Speed: 0.9ms preprocess, 102.2ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/rei/runs/detect/train3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO()\n",
    "\n",
    "model.train(data=\"data.yaml\", epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation with custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
      "WARNING ⚠️ 'ultralytics.yolo.cfg' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.cfg' instead.\n",
      "Ultralytics YOLOv8.0.147 🚀 Python-3.11.4 torch-2.0.0 CPU (Apple M1)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/rei/ml/araya/yolov8_test/data/val/labels.cache... 8 images,\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all          8          8          1      0.989      0.995      0.793\n",
      "Speed: 0.8ms preprocess, 100.9ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/rei/runs/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "!yolo task=detect mode=val model=\"best.pt\" data = data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/15 /Users/rei/ml/araya/yolov8_test/data/test/images/bd29bc18-e385a116-1fed-4fd3-acba-29db1659da3a.jpg: 352x640 4 persons, 179.0ms\n",
      "image 2/15 /Users/rei/ml/araya/yolov8_test/data/test/images/c1f4b19e-3c3c8c68-10e2-11ee-ba5f-e68a90e86460.jpg: 384x640 2 persons, 149.9ms\n",
      "image 3/15 /Users/rei/ml/araya/yolov8_test/data/test/images/c61c9f56-98119b72-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 118.1ms\n",
      "image 4/15 /Users/rei/ml/araya/yolov8_test/data/test/images/c6fd24b8-d9ba4b72-0ac9-49ac-95a6-d4553bef8f46.jpg: 448x640 1 person, 112.8ms\n",
      "image 5/15 /Users/rei/ml/araya/yolov8_test/data/test/images/c96411eb-2cb38da0-10e2-11ee-ba5f-e68a90e86460.jpg: 384x640 1 person, 112.4ms\n",
      "image 6/15 /Users/rei/ml/araya/yolov8_test/data/test/images/c9ebfc2e-9a550dba-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 114.0ms\n",
      "image 7/15 /Users/rei/ml/araya/yolov8_test/data/test/images/cdec6dd7-8f4a2162-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 125.3ms\n",
      "image 8/15 /Users/rei/ml/araya/yolov8_test/data/test/images/d17d0693-95ce0eb8-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 325.6ms\n",
      "image 9/15 /Users/rei/ml/araya/yolov8_test/data/test/images/d3ab0bde-0308a25f-fd01-4ccc-9871-a948fddfe77d.jpg: 288x640 1 person, 102.2ms\n",
      "image 10/15 /Users/rei/ml/araya/yolov8_test/data/test/images/d578e605-94322ba2-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 127.3ms\n",
      "image 11/15 /Users/rei/ml/araya/yolov8_test/data/test/images/d7e84f41-92ce080a-39db-4ceb-85b5-f30997cc16f0.jpg: 416x640 1 person, 171.0ms\n",
      "image 12/15 /Users/rei/ml/araya/yolov8_test/data/test/images/d904e901-9197fa70-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 125.3ms\n",
      "image 13/15 /Users/rei/ml/araya/yolov8_test/data/test/images/dc07c56d-9a03b168-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 125.9ms\n",
      "image 14/15 /Users/rei/ml/araya/yolov8_test/data/test/images/e4fa758d-99611278-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 115.3ms\n",
      "image 15/15 /Users/rei/ml/araya/yolov8_test/data/test/images/e723a8b2-923ad2ea-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 129.6ms\n",
      "Speed: 3.0ms preprocess, 142.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[208, 196, 192],\n",
       "         [208, 196, 192],\n",
       "         [207, 195, 191],\n",
       "         ...,\n",
       "         [191, 179, 179],\n",
       "         [188, 176, 176],\n",
       "         [183, 171, 171]],\n",
       " \n",
       "        [[207, 195, 191],\n",
       "         [207, 195, 191],\n",
       "         [206, 194, 190],\n",
       "         ...,\n",
       "         [190, 178, 178],\n",
       "         [190, 178, 178],\n",
       "         [186, 174, 174]],\n",
       " \n",
       "        [[205, 193, 189],\n",
       "         [205, 193, 189],\n",
       "         [205, 193, 189],\n",
       "         ...,\n",
       "         [189, 177, 177],\n",
       "         [191, 179, 179],\n",
       "         [188, 176, 176]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[176, 164, 160],\n",
       "         [172, 160, 156],\n",
       "         [175, 163, 159],\n",
       "         ...,\n",
       "         [123, 109, 113],\n",
       "         [125, 111, 115],\n",
       "         [126, 112, 116]],\n",
       " \n",
       "        [[168, 156, 152],\n",
       "         [173, 161, 157],\n",
       "         [170, 158, 154],\n",
       "         ...,\n",
       "         [124, 110, 114],\n",
       "         [121, 107, 111],\n",
       "         [119, 105, 109]],\n",
       " \n",
       "        [[168, 156, 152],\n",
       "         [173, 161, 157],\n",
       "         [170, 158, 154],\n",
       "         ...,\n",
       "         [124, 110, 114],\n",
       "         [121, 107, 111],\n",
       "         [119, 105, 109]]], dtype=uint8)\n",
       " orig_shape: (637, 1200)\n",
       " path: '/Users/rei/ml/araya/yolov8_test/data/test/images/bd29bc18-e385a116-1fed-4fd3-acba-29db1659da3a.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 12.736082077026367, 'inference': 178.9710521697998, 'postprocess': 6.916284561157227},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[ 75,  93, 100],\n",
       "         [ 68,  86,  93],\n",
       "         [ 73,  91,  98],\n",
       "         ...,\n",
       "         [ 35,  48,  62],\n",
       "         [ 41,  52,  66],\n",
       "         [ 45,  56,  70]],\n",
       " \n",
       "        [[ 71,  89,  96],\n",
       "         [ 65,  83,  90],\n",
       "         [ 69,  87,  94],\n",
       "         ...,\n",
       "         [ 38,  51,  65],\n",
       "         [ 40,  51,  65],\n",
       "         [ 38,  49,  63]],\n",
       " \n",
       "        [[ 69,  87,  94],\n",
       "         [ 67,  85,  92],\n",
       "         [ 69,  87,  94],\n",
       "         ...,\n",
       "         [ 42,  55,  69],\n",
       "         [ 45,  58,  72],\n",
       "         [ 41,  54,  68]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 58,  75,  84],\n",
       "         [ 56,  73,  82],\n",
       "         [ 55,  72,  81],\n",
       "         ...,\n",
       "         [ 42,  51,  61],\n",
       "         [ 45,  54,  63],\n",
       "         [ 45,  54,  63]],\n",
       " \n",
       "        [[ 57,  74,  83],\n",
       "         [ 60,  77,  86],\n",
       "         [ 57,  74,  83],\n",
       "         ...,\n",
       "         [ 40,  49,  59],\n",
       "         [ 42,  51,  60],\n",
       "         [ 47,  56,  65]],\n",
       " \n",
       "        [[ 60,  77,  86],\n",
       "         [ 61,  78,  87],\n",
       "         [ 51,  68,  77],\n",
       "         ...,\n",
       "         [ 41,  50,  60],\n",
       "         [ 47,  56,  65],\n",
       "         [ 54,  63,  72]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: '/Users/rei/ml/araya/yolov8_test/data/test/images/c1f4b19e-3c3c8c68-10e2-11ee-ba5f-e68a90e86460.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 3.705739974975586, 'inference': 149.9030590057373, 'postprocess': 0.8330345153808594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[177, 193, 200],\n",
       "         [176, 192, 199],\n",
       "         [177, 193, 200],\n",
       "         ...,\n",
       "         [152, 165, 167],\n",
       "         [151, 164, 166],\n",
       "         [150, 163, 165]],\n",
       " \n",
       "        [[177, 193, 200],\n",
       "         [176, 192, 199],\n",
       "         [177, 193, 200],\n",
       "         ...,\n",
       "         [150, 163, 165],\n",
       "         [150, 163, 165],\n",
       "         [149, 162, 164]],\n",
       " \n",
       "        [[176, 192, 199],\n",
       "         [174, 190, 197],\n",
       "         [177, 193, 200],\n",
       "         ...,\n",
       "         [151, 164, 166],\n",
       "         [151, 164, 166],\n",
       "         [151, 164, 166]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 69,  73,  92],\n",
       "         [ 68,  72,  91],\n",
       "         [ 71,  75,  94],\n",
       "         ...,\n",
       "         [ 31,  35,  36],\n",
       "         [ 32,  32,  32],\n",
       "         [ 45,  45,  45]],\n",
       " \n",
       "        [[ 63,  69,  88],\n",
       "         [ 62,  68,  87],\n",
       "         [ 66,  72,  91],\n",
       "         ...,\n",
       "         [ 25,  29,  30],\n",
       "         [ 28,  28,  28],\n",
       "         [ 37,  37,  37]],\n",
       " \n",
       "        [[ 64,  70,  89],\n",
       "         [ 66,  72,  91],\n",
       "         [ 61,  67,  86],\n",
       "         ...,\n",
       "         [ 28,  32,  33],\n",
       "         [ 38,  38,  38],\n",
       "         [ 35,  35,  35]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: '/Users/rei/ml/araya/yolov8_test/data/test/images/c61c9f56-98119b72-31cc-11ee-a456-e68a90e86460.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 2.6481151580810547, 'inference': 118.13807487487793, 'postprocess': 0.7128715515136719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[198, 199, 195],\n",
       "         [196, 198, 192],\n",
       "         [188, 191, 182],\n",
       "         ...,\n",
       "         [148, 155, 152],\n",
       "         [169, 176, 173],\n",
       "         [159, 166, 163]],\n",
       " \n",
       "        [[186, 187, 183],\n",
       "         [201, 203, 197],\n",
       "         [190, 192, 186],\n",
       "         ...,\n",
       "         [134, 139, 137],\n",
       "         [148, 153, 151],\n",
       "         [157, 162, 160]],\n",
       " \n",
       "        [[193, 195, 189],\n",
       "         [195, 197, 191],\n",
       "         [197, 200, 191],\n",
       "         ...,\n",
       "         [165, 172, 169],\n",
       "         [146, 153, 150],\n",
       "         [132, 139, 136]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[247, 245, 244],\n",
       "         [247, 245, 244],\n",
       "         [247, 245, 244],\n",
       "         ...,\n",
       "         [184, 212, 236],\n",
       "         [194, 219, 239],\n",
       "         [197, 221, 239]],\n",
       " \n",
       "        [[245, 243, 242],\n",
       "         [246, 244, 243],\n",
       "         [248, 246, 245],\n",
       "         ...,\n",
       "         [191, 216, 236],\n",
       "         [189, 216, 236],\n",
       "         [193, 219, 236]],\n",
       " \n",
       "        [[245, 243, 242],\n",
       "         [247, 245, 244],\n",
       "         [248, 246, 245],\n",
       "         ...,\n",
       "         [192, 217, 237],\n",
       "         [188, 215, 235],\n",
       "         [192, 217, 237]]], dtype=uint8)\n",
       " orig_shape: (2666, 4000)\n",
       " path: '/Users/rei/ml/araya/yolov8_test/data/test/images/c6fd24b8-d9ba4b72-0ac9-49ac-95a6-d4553bef8f46.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 3.709077835083008, 'inference': 112.84208297729492, 'postprocess': 0.49614906311035156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[44, 66, 71],\n",
       "         [45, 67, 72],\n",
       "         [42, 64, 69],\n",
       "         ...,\n",
       "         [27, 45, 56],\n",
       "         [23, 41, 52],\n",
       "         [21, 39, 50]],\n",
       " \n",
       "        [[45, 67, 72],\n",
       "         [43, 65, 70],\n",
       "         [37, 59, 64],\n",
       "         ...,\n",
       "         [23, 41, 52],\n",
       "         [24, 42, 53],\n",
       "         [23, 41, 52]],\n",
       " \n",
       "        [[42, 64, 69],\n",
       "         [45, 67, 72],\n",
       "         [43, 65, 70],\n",
       "         ...,\n",
       "         [19, 39, 50],\n",
       "         [17, 37, 48],\n",
       "         [22, 42, 53]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[30, 53, 61],\n",
       "         [38, 61, 69],\n",
       "         [35, 58, 66],\n",
       "         ...,\n",
       "         [21, 37, 50],\n",
       "         [26, 42, 55],\n",
       "         [24, 40, 53]],\n",
       " \n",
       "        [[31, 54, 62],\n",
       "         [35, 58, 66],\n",
       "         [32, 55, 63],\n",
       "         ...,\n",
       "         [23, 39, 52],\n",
       "         [23, 39, 52],\n",
       "         [22, 38, 51]],\n",
       " \n",
       "        [[38, 61, 69],\n",
       "         [34, 57, 65],\n",
       "         [30, 53, 61],\n",
       "         ...,\n",
       "         [23, 39, 52],\n",
       "         [18, 34, 47],\n",
       "         [13, 29, 42]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: '/Users/rei/ml/araya/yolov8_test/data/test/images/c96411eb-2cb38da0-10e2-11ee-ba5f-e68a90e86460.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 1.4638900756835938, 'inference': 112.4119758605957, 'postprocess': 0.4830360412597656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[173, 193, 204],\n",
       "         [177, 197, 208],\n",
       "         [178, 198, 209],\n",
       "         ...,\n",
       "         [146, 161, 164],\n",
       "         [145, 160, 162],\n",
       "         [146, 161, 163]],\n",
       " \n",
       "        [[176, 196, 207],\n",
       "         [179, 199, 210],\n",
       "         [178, 198, 209],\n",
       "         ...,\n",
       "         [145, 160, 163],\n",
       "         [144, 159, 161],\n",
       "         [144, 159, 161]],\n",
       " \n",
       "        [[177, 198, 206],\n",
       "         [178, 199, 207],\n",
       "         [178, 199, 207],\n",
       "         ...,\n",
       "         [145, 160, 163],\n",
       "         [144, 159, 161],\n",
       "         [143, 158, 160]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55,  61,  80],\n",
       "         [ 58,  64,  83],\n",
       "         [ 53,  59,  78],\n",
       "         ...,\n",
       "         [ 44,  38,  39],\n",
       "         [ 57,  53,  52],\n",
       "         [ 67,  63,  62]],\n",
       " \n",
       "        [[ 50,  56,  75],\n",
       "         [ 55,  61,  80],\n",
       "         [ 52,  58,  77],\n",
       "         ...,\n",
       "         [ 34,  28,  29],\n",
       "         [ 46,  42,  41],\n",
       "         [ 55,  53,  52]],\n",
       " \n",
       "        [[ 51,  57,  76],\n",
       "         [ 54,  60,  79],\n",
       "         [ 49,  55,  74],\n",
       "         ...,\n",
       "         [ 36,  31,  32],\n",
       "         [ 53,  48,  49],\n",
       "         [ 55,  53,  52]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: '/Users/rei/ml/araya/yolov8_test/data/test/images/c9ebfc2e-9a550dba-31cc-11ee-a456-e68a90e86460.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 1.352071762084961, 'inference': 114.0282154083252, 'postprocess': 0.4992485046386719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 191, 200],\n",
       "         [176, 193, 202],\n",
       "         [175, 192, 201],\n",
       "         ...,\n",
       "         [146, 163, 166],\n",
       "         [147, 164, 167],\n",
       "         [149, 166, 169]],\n",
       " \n",
       "        [[171, 188, 197],\n",
       "         [173, 190, 199],\n",
       "         [174, 191, 200],\n",
       "         ...,\n",
       "         [147, 164, 167],\n",
       "         [148, 165, 168],\n",
       "         [149, 166, 169]],\n",
       " \n",
       "        [[175, 192, 201],\n",
       "         [175, 192, 201],\n",
       "         [173, 190, 199],\n",
       "         ...,\n",
       "         [149, 166, 169],\n",
       "         [150, 167, 170],\n",
       "         [150, 167, 170]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  60,  85],\n",
       "         [ 55,  59,  84],\n",
       "         [ 51,  55,  79],\n",
       "         ...,\n",
       "         [ 34,  25,  28],\n",
       "         [ 39,  31,  32],\n",
       "         [ 50,  42,  43]],\n",
       " \n",
       "        [[ 58,  62,  87],\n",
       "         [ 55,  59,  84],\n",
       "         [ 56,  58,  82],\n",
       "         ...,\n",
       "         [ 35,  26,  29],\n",
       "         [ 31,  22,  25],\n",
       "         [ 48,  39,  42]],\n",
       " \n",
       "        [[ 60,  64,  89],\n",
       "         [ 59,  63,  88],\n",
       "         [ 60,  62,  86],\n",
       "         ...,\n",
       "         [ 27,  18,  21],\n",
       "         [ 29,  20,  23],\n",
       "         [ 40,  31,  34]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: '/Users/rei/ml/araya/yolov8_test/data/test/images/cdec6dd7-8f4a2162-31cc-11ee-a456-e68a90e86460.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 1.5780925750732422, 'inference': 125.27275085449219, 'postprocess': 0.8230209350585938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[176, 189, 197],\n",
       "         [174, 187, 195],\n",
       "         [171, 184, 192],\n",
       "         ...,\n",
       "         [146, 158, 162],\n",
       "         [142, 154, 158],\n",
       "         [146, 158, 162]],\n",
       " \n",
       "        [[173, 186, 194],\n",
       "         [176, 189, 197],\n",
       "         [172, 185, 193],\n",
       "         ...,\n",
       "         [145, 157, 161],\n",
       "         [140, 152, 156],\n",
       "         [139, 151, 155]],\n",
       " \n",
       "        [[174, 187, 195],\n",
       "         [177, 190, 198],\n",
       "         [174, 187, 195],\n",
       "         ...,\n",
       "         [140, 155, 158],\n",
       "         [140, 155, 158],\n",
       "         [138, 153, 156]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 58,  59,  79],\n",
       "         [ 60,  61,  81],\n",
       "         [ 57,  58,  78],\n",
       "         ...,\n",
       "         [ 33,  27,  38],\n",
       "         [ 40,  31,  41],\n",
       "         [ 44,  35,  45]],\n",
       " \n",
       "        [[ 56,  57,  77],\n",
       "         [ 57,  58,  78],\n",
       "         [ 58,  59,  79],\n",
       "         ...,\n",
       "         [ 34,  28,  39],\n",
       "         [ 34,  25,  35],\n",
       "         [ 40,  31,  41]],\n",
       " \n",
       "        [[ 56,  57,  77],\n",
       "         [ 53,  54,  74],\n",
       "         [ 58,  59,  79],\n",
       "         ...,\n",
       "         [ 21,  15,  26],\n",
       "         [ 35,  26,  36],\n",
       "         [ 40,  31,  41]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: '/Users/rei/ml/araya/yolov8_test/data/test/images/d17d0693-95ce0eb8-31cc-11ee-a456-e68a90e86460.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 2.691030502319336, 'inference': 325.5910873413086, 'postprocess': 0.6959438323974609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[246, 247, 245],\n",
       "         [246, 247, 245],\n",
       "         [246, 247, 245],\n",
       "         ...,\n",
       "         [224, 231, 234],\n",
       "         [224, 231, 234],\n",
       "         [224, 231, 234]],\n",
       " \n",
       "        [[246, 247, 245],\n",
       "         [246, 247, 245],\n",
       "         [246, 247, 245],\n",
       "         ...,\n",
       "         [224, 231, 234],\n",
       "         [224, 231, 234],\n",
       "         [224, 231, 234]],\n",
       " \n",
       "        [[246, 247, 245],\n",
       "         [246, 247, 245],\n",
       "         [246, 247, 245],\n",
       "         ...,\n",
       "         [224, 231, 234],\n",
       "         [224, 231, 234],\n",
       "         [224, 231, 234]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[213, 212, 214],\n",
       "         [213, 212, 214],\n",
       "         [213, 212, 214],\n",
       "         ...,\n",
       "         [ 74,  78,  89],\n",
       "         [ 73,  77,  88],\n",
       "         [ 72,  76,  87]],\n",
       " \n",
       "        [[214, 213, 215],\n",
       "         [213, 212, 214],\n",
       "         [212, 211, 213],\n",
       "         ...,\n",
       "         [ 74,  78,  89],\n",
       "         [ 73,  77,  88],\n",
       "         [ 72,  76,  87]],\n",
       " \n",
       "        [[214, 213, 215],\n",
       "         [213, 212, 214],\n",
       "         [212, 211, 213],\n",
       "         ...,\n",
       "         [ 74,  78,  89],\n",
       "         [ 73,  77,  88],\n",
       "         [ 72,  76,  87]]], dtype=uint8)\n",
       " orig_shape: (896, 2048)\n",
       " path: '/Users/rei/ml/araya/yolov8_test/data/test/images/d3ab0bde-0308a25f-fd01-4ccc-9871-a948fddfe77d.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 2.105236053466797, 'inference': 102.15973854064941, 'postprocess': 0.5800724029541016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[175, 194, 209],\n",
       "         [175, 194, 209],\n",
       "         [177, 196, 211],\n",
       "         ...,\n",
       "         [137, 156, 161],\n",
       "         [136, 155, 160],\n",
       "         [140, 159, 164]],\n",
       " \n",
       "        [[171, 190, 205],\n",
       "         [174, 193, 208],\n",
       "         [176, 195, 210],\n",
       "         ...,\n",
       "         [138, 157, 162],\n",
       "         [137, 156, 161],\n",
       "         [138, 157, 162]],\n",
       " \n",
       "        [[171, 190, 205],\n",
       "         [175, 194, 209],\n",
       "         [175, 194, 209],\n",
       "         ...,\n",
       "         [137, 156, 161],\n",
       "         [138, 157, 162],\n",
       "         [137, 156, 161]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  63,  88],\n",
       "         [ 60,  67,  92],\n",
       "         [ 61,  68,  93],\n",
       "         ...,\n",
       "         [ 39,  35,  46],\n",
       "         [ 44,  43,  53],\n",
       "         [ 48,  47,  57]],\n",
       " \n",
       "        [[ 55,  62,  87],\n",
       "         [ 59,  66,  91],\n",
       "         [ 57,  64,  89],\n",
       "         ...,\n",
       "         [ 34,  30,  41],\n",
       "         [ 38,  37,  47],\n",
       "         [ 43,  42,  52]],\n",
       " \n",
       "        [[ 60,  67,  92],\n",
       "         [ 62,  69,  94],\n",
       "         [ 56,  63,  88],\n",
       "         ...,\n",
       "         [ 35,  31,  42],\n",
       "         [ 39,  38,  48],\n",
       "         [ 44,  43,  53]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: '/Users/rei/ml/araya/yolov8_test/data/test/images/d578e605-94322ba2-31cc-11ee-a456-e68a90e86460.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 1.7821788787841797, 'inference': 127.26688385009766, 'postprocess': 0.6692409515380859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[159, 244, 240],\n",
       "         [159, 244, 240],\n",
       "         [159, 244, 240],\n",
       "         ...,\n",
       "         [183, 187, 175],\n",
       "         [184, 188, 176],\n",
       "         [185, 189, 177]],\n",
       " \n",
       "        [[160, 245, 241],\n",
       "         [160, 245, 241],\n",
       "         [160, 245, 241],\n",
       "         ...,\n",
       "         [184, 188, 176],\n",
       "         [185, 189, 177],\n",
       "         [185, 189, 177]],\n",
       " \n",
       "        [[161, 246, 242],\n",
       "         [161, 246, 242],\n",
       "         [161, 246, 242],\n",
       "         ...,\n",
       "         [184, 188, 176],\n",
       "         [185, 189, 177],\n",
       "         [186, 190, 178]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[147, 163, 179],\n",
       "         [146, 162, 178],\n",
       "         [146, 162, 178],\n",
       "         ...,\n",
       "         [ 33,  35,  36],\n",
       "         [ 32,  34,  35],\n",
       "         [ 31,  33,  34]],\n",
       " \n",
       "        [[147, 163, 179],\n",
       "         [147, 163, 179],\n",
       "         [146, 162, 178],\n",
       "         ...,\n",
       "         [ 35,  37,  38],\n",
       "         [ 32,  36,  37],\n",
       "         [ 34,  36,  37]],\n",
       " \n",
       "        [[149, 165, 178],\n",
       "         [148, 164, 177],\n",
       "         [148, 164, 177],\n",
       "         ...,\n",
       "         [ 36,  39,  43],\n",
       "         [ 34,  39,  42],\n",
       "         [ 35,  38,  42]]], dtype=uint8)\n",
       " orig_shape: (829, 1365)\n",
       " path: '/Users/rei/ml/araya/yolov8_test/data/test/images/d7e84f41-92ce080a-39db-4ceb-85b5-f30997cc16f0.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 2.6731491088867188, 'inference': 170.9887981414795, 'postprocess': 0.7090568542480469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 191, 200],\n",
       "         [176, 193, 202],\n",
       "         [176, 193, 202],\n",
       "         ...,\n",
       "         [192, 214, 212],\n",
       "         [194, 216, 214],\n",
       "         [194, 216, 214]],\n",
       " \n",
       "        [[171, 188, 197],\n",
       "         [173, 190, 199],\n",
       "         [174, 191, 200],\n",
       "         ...,\n",
       "         [191, 213, 211],\n",
       "         [193, 215, 213],\n",
       "         [193, 215, 213]],\n",
       " \n",
       "        [[173, 190, 199],\n",
       "         [174, 191, 200],\n",
       "         [173, 190, 199],\n",
       "         ...,\n",
       "         [191, 213, 211],\n",
       "         [192, 214, 212],\n",
       "         [191, 213, 211]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 68,  75,  95],\n",
       "         [ 65,  72,  92],\n",
       "         [ 63,  70,  89],\n",
       "         ...,\n",
       "         [ 48,  41,  46],\n",
       "         [ 50,  40,  46],\n",
       "         [ 58,  48,  54]],\n",
       " \n",
       "        [[ 70,  76,  95],\n",
       "         [ 65,  71,  90],\n",
       "         [ 64,  70,  89],\n",
       "         ...,\n",
       "         [ 45,  38,  43],\n",
       "         [ 36,  26,  32],\n",
       "         [ 51,  41,  47]],\n",
       " \n",
       "        [[ 70,  76,  95],\n",
       "         [ 71,  77,  96],\n",
       "         [ 63,  69,  88],\n",
       "         ...,\n",
       "         [ 33,  26,  31],\n",
       "         [ 20,  10,  16],\n",
       "         [ 44,  34,  40]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: '/Users/rei/ml/araya/yolov8_test/data/test/images/d904e901-9197fa70-31cc-11ee-a456-e68a90e86460.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 2.0439624786376953, 'inference': 125.30398368835449, 'postprocess': 0.6680488586425781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[179, 198, 205],\n",
       "         [177, 196, 203],\n",
       "         [176, 195, 202],\n",
       "         ...,\n",
       "         [141, 158, 161],\n",
       "         [143, 159, 165],\n",
       "         [144, 160, 166]],\n",
       " \n",
       "        [[179, 198, 205],\n",
       "         [178, 197, 204],\n",
       "         [177, 196, 203],\n",
       "         ...,\n",
       "         [143, 160, 163],\n",
       "         [144, 160, 166],\n",
       "         [142, 158, 164]],\n",
       " \n",
       "        [[177, 196, 203],\n",
       "         [177, 196, 203],\n",
       "         [177, 196, 203],\n",
       "         ...,\n",
       "         [150, 165, 168],\n",
       "         [146, 161, 164],\n",
       "         [144, 159, 162]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 63,  70,  90],\n",
       "         [ 61,  68,  88],\n",
       "         [ 65,  70,  91],\n",
       "         ...,\n",
       "         [ 47,  43,  48],\n",
       "         [ 44,  40,  45],\n",
       "         [ 51,  47,  52]],\n",
       " \n",
       "        [[ 65,  72,  92],\n",
       "         [ 61,  68,  88],\n",
       "         [ 63,  70,  89],\n",
       "         ...,\n",
       "         [ 44,  40,  46],\n",
       "         [ 43,  39,  45],\n",
       "         [ 47,  43,  49]],\n",
       " \n",
       "        [[ 61,  68,  88],\n",
       "         [ 58,  65,  85],\n",
       "         [ 63,  70,  89],\n",
       "         ...,\n",
       "         [ 42,  38,  44],\n",
       "         [ 42,  38,  44],\n",
       "         [ 45,  41,  47]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: '/Users/rei/ml/araya/yolov8_test/data/test/images/dc07c56d-9a03b168-31cc-11ee-a456-e68a90e86460.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 2.062082290649414, 'inference': 125.88906288146973, 'postprocess': 0.7081031799316406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[176, 194, 201],\n",
       "         [170, 188, 195],\n",
       "         [173, 191, 198],\n",
       "         ...,\n",
       "         [151, 166, 168],\n",
       "         [149, 164, 166],\n",
       "         [149, 164, 166]],\n",
       " \n",
       "        [[173, 191, 198],\n",
       "         [180, 198, 205],\n",
       "         [177, 195, 202],\n",
       "         ...,\n",
       "         [148, 163, 165],\n",
       "         [149, 164, 166],\n",
       "         [150, 165, 167]],\n",
       " \n",
       "        [[174, 192, 199],\n",
       "         [180, 198, 205],\n",
       "         [176, 194, 201],\n",
       "         ...,\n",
       "         [149, 164, 166],\n",
       "         [149, 164, 166],\n",
       "         [148, 163, 165]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 65,  70,  95],\n",
       "         [ 62,  67,  92],\n",
       "         [ 57,  63,  86],\n",
       "         ...,\n",
       "         [ 40,  39,  41],\n",
       "         [ 41,  39,  39],\n",
       "         [ 56,  54,  54]],\n",
       " \n",
       "        [[ 64,  69,  94],\n",
       "         [ 63,  68,  93],\n",
       "         [ 61,  67,  90],\n",
       "         ...,\n",
       "         [ 43,  42,  44],\n",
       "         [ 41,  38,  40],\n",
       "         [ 48,  45,  47]],\n",
       " \n",
       "        [[ 66,  71,  96],\n",
       "         [ 61,  66,  91],\n",
       "         [ 64,  70,  93],\n",
       "         ...,\n",
       "         [ 31,  30,  32],\n",
       "         [ 38,  35,  37],\n",
       "         [ 39,  36,  38]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: '/Users/rei/ml/araya/yolov8_test/data/test/images/e4fa758d-99611278-31cc-11ee-a456-e68a90e86460.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 2.045869827270508, 'inference': 115.34905433654785, 'postprocess': 0.7729530334472656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[173, 194, 209],\n",
       "         [173, 194, 209],\n",
       "         [173, 194, 209],\n",
       "         ...,\n",
       "         [140, 159, 166],\n",
       "         [141, 160, 167],\n",
       "         [140, 159, 166]],\n",
       " \n",
       "        [[172, 193, 208],\n",
       "         [172, 193, 208],\n",
       "         [172, 193, 208],\n",
       "         ...,\n",
       "         [138, 157, 164],\n",
       "         [138, 157, 164],\n",
       "         [138, 157, 164]],\n",
       " \n",
       "        [[174, 195, 210],\n",
       "         [174, 195, 210],\n",
       "         [174, 195, 210],\n",
       "         ...,\n",
       "         [138, 157, 164],\n",
       "         [140, 159, 166],\n",
       "         [141, 160, 167]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 48,  56,  85],\n",
       "         [ 49,  57,  86],\n",
       "         [ 48,  56,  85],\n",
       "         ...,\n",
       "         [ 39,  36,  38],\n",
       "         [ 27,  26,  30],\n",
       "         [ 41,  40,  44]],\n",
       " \n",
       "        [[ 49,  57,  86],\n",
       "         [ 49,  57,  86],\n",
       "         [ 47,  55,  84],\n",
       "         ...,\n",
       "         [ 30,  27,  29],\n",
       "         [ 26,  25,  29],\n",
       "         [ 33,  32,  36]],\n",
       " \n",
       "        [[ 52,  60,  89],\n",
       "         [ 50,  58,  87],\n",
       "         [ 47,  55,  84],\n",
       "         ...,\n",
       "         [ 21,  18,  20],\n",
       "         [ 21,  20,  24],\n",
       "         [ 35,  34,  38]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: '/Users/rei/ml/araya/yolov8_test/data/test/images/e723a8b2-923ad2ea-31cc-11ee-a456-e68a90e86460.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 1.7981529235839844, 'inference': 129.55784797668457, 'postprocess': 0.7190704345703125}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO(\"best.pt\")\n",
    "test_img = 'data/test/images'\n",
    "model.predict(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
      "WARNING ⚠️ 'ultralytics.yolo.cfg' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.cfg' instead.\n",
      "Ultralytics YOLOv8.0.147 🚀 Python-3.11.4 torch-2.0.0 CPU (Apple M1)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
      "\n",
      "image 1/15 /Users/rei/ml/araya/yolov8_test/data/test/images/bd29bc18-e385a116-1fed-4fd3-acba-29db1659da3a.jpg: 352x640 4 persons, 198.2ms\n",
      "image 2/15 /Users/rei/ml/araya/yolov8_test/data/test/images/c1f4b19e-3c3c8c68-10e2-11ee-ba5f-e68a90e86460.jpg: 384x640 2 persons, 186.3ms\n",
      "image 3/15 /Users/rei/ml/araya/yolov8_test/data/test/images/c61c9f56-98119b72-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 133.8ms\n",
      "image 4/15 /Users/rei/ml/araya/yolov8_test/data/test/images/c6fd24b8-d9ba4b72-0ac9-49ac-95a6-d4553bef8f46.jpg: 448x640 1 person, 130.2ms\n",
      "image 5/15 /Users/rei/ml/araya/yolov8_test/data/test/images/c96411eb-2cb38da0-10e2-11ee-ba5f-e68a90e86460.jpg: 384x640 1 person, 113.2ms\n",
      "image 6/15 /Users/rei/ml/araya/yolov8_test/data/test/images/c9ebfc2e-9a550dba-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 125.6ms\n",
      "image 7/15 /Users/rei/ml/araya/yolov8_test/data/test/images/cdec6dd7-8f4a2162-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 141.0ms\n",
      "image 8/15 /Users/rei/ml/araya/yolov8_test/data/test/images/d17d0693-95ce0eb8-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 138.3ms\n",
      "image 9/15 /Users/rei/ml/araya/yolov8_test/data/test/images/d3ab0bde-0308a25f-fd01-4ccc-9871-a948fddfe77d.jpg: 288x640 1 person, 115.7ms\n",
      "image 10/15 /Users/rei/ml/araya/yolov8_test/data/test/images/d578e605-94322ba2-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 134.4ms\n",
      "image 11/15 /Users/rei/ml/araya/yolov8_test/data/test/images/d7e84f41-92ce080a-39db-4ceb-85b5-f30997cc16f0.jpg: 416x640 1 person, 131.2ms\n",
      "image 12/15 /Users/rei/ml/araya/yolov8_test/data/test/images/d904e901-9197fa70-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 188.9ms\n",
      "image 13/15 /Users/rei/ml/araya/yolov8_test/data/test/images/dc07c56d-9a03b168-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 269.6ms\n",
      "image 14/15 /Users/rei/ml/araya/yolov8_test/data/test/images/e4fa758d-99611278-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 224.7ms\n",
      "image 15/15 /Users/rei/ml/araya/yolov8_test/data/test/images/e723a8b2-923ad2ea-31cc-11ee-a456-e68a90e86460.jpg: 384x640 1 person, 123.3ms\n",
      "Speed: 2.2ms preprocess, 156.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/rei/runs/detect/predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_img = '/Users/rei/ml/araya/yolov8_test/data/test/images'\n",
    "!yolo task=detect mode=predict model='best.pt' conf=0.25 source='/Users/rei/ml/araya/yolov8_test/data/test/images'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aryenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
